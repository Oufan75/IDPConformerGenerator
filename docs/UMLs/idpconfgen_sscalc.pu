@startuml

start

:idpconfgen //sscalc//;
note right
    This pipeline currently uses //mkdssp//
    but can be configured to others by dispaching
    different functions without altering the main
    pipeline
end note

partition #LIGHTGREY Examples {
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs/ -o dssp.json -n;
    note right
        where //filtered_pdbs// is a folder
        containing //*.pdb// files.
    end note
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs.tar -o dssp.json -n;
    note right
        where //filtered_pdb.tar// is a
        tarfile containing pdb files.
    end note
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs.tar -o dssp.json [-rd|--reduced] -n;
    note right
        //reduced// converts all
        DSSP tags to H, E, or L
    end note
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs.tar -o dssp.json -d splitted.json -n;
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs.tar -o dssp.json -u previous.json -d splitted.json -n;
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs.tar -o dssp.json -u previous.json -d splitted.json -m 2 -n;
    #WHITE:$ idpconfgen sscalc mkdssp filtered_pdbs.tar -o dssp.json -u previous.json -d splitted.json -m 2 -n -c 1000;
    }

if (input data) then (tar file)
    :unpack tar to tmp dir;
    note left
        uses only //.pdb// files
    end note
    :tmp dir is deleted at the end;
else (folder)
    :uses //.pdb// files in that folder;
endif

if (--complete) then (reads previous)
    :reads previous //sscalc//
    information file, stores it
    for later;
    note left
        Entries with the same ID
        are overwritten
    end note
else (not given)
    :starts a blank output file;
endif

#FFD3F2:repeat ://for each chunk of paths//;
fork

:subprocess //mkdssp// for the PDB;
note right
    At this stage, single chain
    PDBs are expected;
end note
:identify backbone discontinuity
    as given by DSSP;
note right
    This considers also carbonyl oxigen,
    different from my initial approach;
end note
:collects:
        residue number
        Sec Str character
        FASTA character;

:open PDB file;
 while (for each backbone segment)

if (length segment) then (< minimum)
    :ignore;
    end
elseif (records) then (are all HETATM)
    :ignore;
    end
else (all good)
    :saves segment from PDB in new file;
endif

endwhile (no more segments)
end fork
note right #whitesmoke
    This process is performed in parallel
    where cores extract PDBs from the queue
    until the queue is exhausted
end note
if (chunk finished to process) then (TAR)
    :save in TAR file;
else (folder)
    :save PDB/CIFs to folder;
endif
backward://launch another chunk//;
repeat while (//more PDBs to process?//)

if (--complete) then (updates previous)
    :updates previous //sscalc//
    information file, with the information
    generated in this run;
    note left
        Entries with the same ID
        are overwritten
    end note
else (not given)
    :saves the secondary structure informatio
    from this run;
endif
if (save data to disk) then (JSON)
    :saves dictionary to //.json// file;
else (PICKLE)
    :saves dictionary to //pickle// object;
    note right
        //pickle// currently disable for security,
        adds nothing to //json//.
    end note
endif

stop

@enduml
